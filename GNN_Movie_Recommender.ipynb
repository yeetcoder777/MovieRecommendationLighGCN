{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ GNN-Based Movie Recommendation System\n",
    "## Using LightGCN on MovieLens 100K Dataset\n",
    "\n",
    "This notebook builds a **Graph Neural Network** recommender where:\n",
    "- **Nodes**: Users and Movies  \n",
    "- **Edges**: User-Movie interactions (ratings ‚â• 4)\n",
    "\n",
    "### What You'll Learn:\n",
    "1. How to construct a bipartite graph for recommendations\n",
    "2. How LightGCN learns embeddings through message passing\n",
    "3. How peer influence propagates through multi-hop connections\n",
    "4. How to generate and evaluate recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import degree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Download and Load MovieLens 100K\n",
    "\n",
    "The dataset contains:\n",
    "- **100,000 ratings** from 943 users on 1,682 movies\n",
    "- User demographics (age, gender, occupation)\n",
    "- Movie genres (19 genres as one-hot vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MovieLens 100K...\n",
      "Done!\n",
      "Ratings: 100,000, Users: 943, Movies: 1682\n"
     ]
    }
   ],
   "source": [
    "def download_movielens():\n",
    "    data_dir = 'ml-100k'\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(\"Downloading MovieLens 100K...\")\n",
    "        url = 'https://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "        urllib.request.urlretrieve(url, 'ml-100k.zip')\n",
    "        with zipfile.ZipFile('ml-100k.zip', 'r') as z:\n",
    "            z.extractall('.')\n",
    "        os.remove('ml-100k.zip')\n",
    "        print(\"Done!\")\n",
    "    return data_dir\n",
    "\n",
    "def load_data(data_dir):\n",
    "    ratings = pd.read_csv(f'{data_dir}/u.data', sep='\\t',\n",
    "                         names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "    users = pd.read_csv(f'{data_dir}/u.user', sep='|',\n",
    "                       names=['user_id', 'age', 'gender', 'occupation', 'zip'],\n",
    "                       encoding='latin-1')\n",
    "    movies = pd.read_csv(f'{data_dir}/u.item', sep='|', encoding='latin-1',\n",
    "                        names=['movie_id', 'title', 'release', 'video_release', 'url',\n",
    "                               'unknown', 'Action', 'Adventure', 'Animation', 'Children',\n",
    "                               'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "                               'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance',\n",
    "                               'Sci-Fi', 'Thriller', 'War', 'Western'])\n",
    "    print(f\"Ratings: {len(ratings):,}, Users: {len(users)}, Movies: {len(movies)}\")\n",
    "    return ratings, users, movies\n",
    "\n",
    "data_dir = download_movielens()\n",
    "ratings_df, users_df, movies_df = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Build the Bipartite Graph\n",
    "\n",
    "### What is a Bipartite Graph?\n",
    "A graph with **two node types** where edges only connect **different types**:\n",
    "\n",
    "```\n",
    "Users              Movies\n",
    "  U1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ M1 (Toy Story)\n",
    "  U2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ M2 (Star Wars)  \n",
    "  U3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ M3 (Matrix)\n",
    "```\n",
    "\n",
    "Users connect to movies they rated highly (‚â•4 stars).\n",
    "\n",
    "### Why This Works for Recommendations:\n",
    "- After message passing, **similar users** get **similar embeddings**\n",
    "- A user's embedding naturally \"points toward\" movies they'd like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: 943 users, 1682 movies, 55375 positive edges\n",
      "Train: 44675 edges, Test: 10700 edges\n"
     ]
    }
   ],
   "source": [
    "class MovieLensGraph:\n",
    "    def __init__(self, ratings_df, users_df, movies_df, threshold=4):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # Create ID mappings\n",
    "        self.user_ids = ratings_df['user_id'].unique()\n",
    "        self.movie_ids = ratings_df['movie_id'].unique()\n",
    "        self.user_to_idx = {u: i for i, u in enumerate(self.user_ids)}\n",
    "        self.movie_to_idx = {m: i for i, m in enumerate(self.movie_ids)}\n",
    "        self.idx_to_user = {i: u for u, i in self.user_to_idx.items()}\n",
    "        self.idx_to_movie = {i: m for m, i in self.movie_to_idx.items()}\n",
    "        \n",
    "        self.num_users = len(self.user_ids)\n",
    "        self.num_movies = len(self.movie_ids)\n",
    "        self.num_nodes = self.num_users + self.num_movies\n",
    "        \n",
    "        self.users_df = users_df\n",
    "        self.movies_df = movies_df\n",
    "        self.genres = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy',\n",
    "                      'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir',\n",
    "                      'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "                      'Thriller', 'War', 'Western']\n",
    "        \n",
    "        # Build edges from positive interactions\n",
    "        pos = ratings_df[ratings_df['rating'] >= threshold]\n",
    "        user_idx = [self.user_to_idx[u] for u in pos['user_id']]\n",
    "        movie_idx = [self.num_users + self.movie_to_idx[m] for m in pos['movie_id']]\n",
    "        \n",
    "        # Bidirectional edges\n",
    "        self.edge_index = torch.tensor([user_idx + movie_idx, movie_idx + user_idx])\n",
    "        \n",
    "        # Store user interactions\n",
    "        self.user_items = defaultdict(set)\n",
    "        for _, r in pos.iterrows():\n",
    "            self.user_items[self.user_to_idx[r['user_id']]].add(self.movie_to_idx[r['movie_id']])\n",
    "        \n",
    "        print(f\"Graph: {self.num_users} users, {self.num_movies} movies, {len(pos)} positive edges\")\n",
    "    \n",
    "    def train_test_split(self, test_ratio=0.2):\n",
    "        train_e, test_e = [], []\n",
    "        for u, movies in self.user_items.items():\n",
    "            m_list = list(movies)\n",
    "            np.random.shuffle(m_list)\n",
    "            n_test = max(1, int(len(m_list) * test_ratio)) if len(m_list) > 1 else 0\n",
    "            test_e.extend([(u, m + self.num_users) for m in m_list[:n_test]])\n",
    "            train_e.extend([(u, m + self.num_users) for m in m_list[n_test:]])\n",
    "        \n",
    "        src = [e[0] for e in train_e] + [e[1] for e in train_e]\n",
    "        dst = [e[1] for e in train_e] + [e[0] for e in train_e]\n",
    "        self.train_edges = torch.tensor([src, dst])\n",
    "        self.test_edges = test_e\n",
    "        print(f\"Train: {len(train_e)} edges, Test: {len(test_e)} edges\")\n",
    "        return self.train_edges, self.test_edges\n",
    "\n",
    "graph = MovieLensGraph(ratings_df, users_df, movies_df)\n",
    "train_edges, test_edges = graph.train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: LightGCN Model\n",
    "\n",
    "### How LightGCN Works:\n",
    "\n",
    "1. **Start**: Each user/movie has a random embedding vector\n",
    "2. **Message Passing**: Each node aggregates neighbors' embeddings  \n",
    "3. **Multi-layer**: Stack K layers to capture K-hop neighborhoods\n",
    "4. **Final Embedding**: Average of all layer outputs\n",
    "\n",
    "### The Key Formula:\n",
    "```\n",
    "e_new = Œ£ (1/‚àödeg_i √ó 1/‚àödeg_j) √ó e_neighbor\n",
    "```\n",
    "\n",
    "**No weights, no activations** - just normalized aggregation!\n",
    "\n",
    "### Why Simpler is Better:\n",
    "Standard GCNs have weight matrices and activations. For recommendations (where we learn embeddings from scratch), this complexity causes overfitting. LightGCN removes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCNConv(MessagePassing):\n",
    "    \"\"\"LightGCN layer: aggregates neighbor embeddings with degree normalization.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(aggr='add')\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "    \n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embed_dim=64, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding = nn.Embedding(num_users + num_items, embed_dim)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        self.convs = nn.ModuleList([LightGCNConv() for _ in range(num_layers)])\n",
    "    \n",
    "    def forward(self, edge_index):\n",
    "        x = self.embedding.weight\n",
    "        all_emb = [x]\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            all_emb.append(x)\n",
    "        return torch.stack(all_emb, dim=1).mean(dim=1)  # Average all layers\n",
    "    \n",
    "    def get_embeddings(self, edge_index):\n",
    "        emb = self.forward(edge_index)\n",
    "        return emb[:self.num_users], emb[self.num_users:]\n",
    "    \n",
    "    def predict(self, users, items, edge_index):\n",
    "        u_emb, i_emb = self.get_embeddings(edge_index)\n",
    "        return (u_emb[users] * i_emb[items]).sum(dim=1)  # Dot product\n",
    "\n",
    "model = LightGCN(graph.num_users, graph.num_movies, embed_dim=64, num_layers=3).to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Training with BPR Loss\n",
    "\n",
    "### BPR (Bayesian Personalized Ranking):\n",
    "\n",
    "For each triplet `(user, positive_item, negative_item)`:\n",
    "```\n",
    "Loss = -log(sigmoid(score_pos - score_neg))\n",
    "```\n",
    "\n",
    "This pushes **positive items to rank higher** than negative items.\n",
    "\n",
    "### Why BPR instead of MSE?\n",
    "- We care about **ranking**, not exact rating prediction\n",
    "- Directly optimizes what we want: correct ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    return -torch.mean(F.logsigmoid(pos_scores - neg_scores))\n",
    "\n",
    "def sample_negatives(users, num_items, user_items):\n",
    "    negs = []\n",
    "    for u in users.cpu().numpy():\n",
    "        while True:\n",
    "            n = np.random.randint(num_items)\n",
    "            if n not in user_items.get(u, set()):\n",
    "                negs.append(n)\n",
    "                break\n",
    "    return torch.tensor(negs)\n",
    "\n",
    "def train_epoch(model, optimizer, edges, graph, device, batch_size=1024):\n",
    "    model.train()\n",
    "    pos = edges[:, edges[0] < graph.num_users]\n",
    "    perm = torch.randperm(pos.shape[1])\n",
    "    pos = pos[:, perm]\n",
    "    \n",
    "    total_loss = 0\n",
    "    n_batches = 0\n",
    "    for i in range(0, pos.shape[1], batch_size):\n",
    "        batch = pos[:, i:i+batch_size]\n",
    "        users = batch[0].to(device)\n",
    "        pos_items = (batch[1] - graph.num_users).to(device)\n",
    "        neg_items = sample_negatives(users, graph.num_movies, graph.user_items).to(device)\n",
    "        \n",
    "        pos_scores = model.predict(users, pos_items, edges.to(device))\n",
    "        neg_scores = model.predict(users, neg_items, edges.to(device))\n",
    "        \n",
    "        loss = bpr_loss(pos_scores, neg_scores)\n",
    "        reg = 1e-4 * (model.embedding.weight.norm(2) ** 2) / len(users)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        (loss + reg).backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "    \n",
    "    return total_loss / n_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Evaluation Metrics\n",
    "\n",
    "- **Hit@K**: Did ANY test item appear in top-K recommendations?\n",
    "- **NDCG@K**: Normalized ranking quality (rewards items ranked higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, edges, graph, test_edges, Ks=[5, 10, 20]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        u_emb, i_emb = model.get_embeddings(edges.to(device))\n",
    "        u_emb, i_emb = u_emb.cpu(), i_emb.cpu()\n",
    "    \n",
    "    user_tests = defaultdict(set)\n",
    "    for u, m in test_edges:\n",
    "        user_tests[u].add(m - graph.num_users)\n",
    "    \n",
    "    hits = {k: [] for k in Ks}\n",
    "    ndcgs = {k: [] for k in Ks}\n",
    "    \n",
    "    for u, test_items in user_tests.items():\n",
    "        scores = torch.mm(u_emb[u:u+1], i_emb.t()).squeeze()\n",
    "        for m in graph.user_items.get(u, []):\n",
    "            scores[m] = float('-inf')  # Mask seen items\n",
    "        \n",
    "        _, topk = torch.topk(scores, max(Ks))\n",
    "        topk = topk.numpy()\n",
    "        \n",
    "        for k in Ks:\n",
    "            top = set(topk[:k])\n",
    "            hits[k].append(1.0 if top & test_items else 0.0)\n",
    "            dcg = sum(1/np.log2(i+2) for i, m in enumerate(topk[:k]) if m in test_items)\n",
    "            idcg = sum(1/np.log2(i+2) for i in range(min(len(test_items), k)))\n",
    "            ndcgs[k].append(dcg/idcg if idcg > 0 else 0)\n",
    "    \n",
    "    results = {}\n",
    "    for k in Ks:\n",
    "        results[f'Hit@{k}'] = np.mean(hits[k])\n",
    "        results[f'NDCG@{k}'] = np.mean(ndcgs[k])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "losses, metrics_history = [], []\n",
    "\n",
    "print(\"Training LightGCN...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(50):\n",
    "    loss = train_epoch(model, optimizer, train_edges, graph, device)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        metrics = evaluate(model, train_edges, graph, test_edges)\n",
    "        metrics_history.append(metrics)\n",
    "        print(f\"Epoch {epoch+1:3d} | Loss: {loss:.4f} | Hit@10: {metrics['Hit@10']:.4f} | NDCG@10: {metrics['NDCG@10']:.4f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nFinal Results:\")\n",
    "final = evaluate(model, train_edges, graph, test_edges)\n",
    "for k, v in final.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Generate Recommendations\n",
    "\n",
    "Now we can recommend movies to any user by computing similarity between their embedding and all movie embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(model, user_idx, graph, edges, top_k=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        u_emb, i_emb = model.get_embeddings(edges.to(device))\n",
    "    \n",
    "    scores = torch.mm(u_emb[user_idx:user_idx+1].cpu(), i_emb.cpu().t()).squeeze()\n",
    "    \n",
    "    # Mask movies already seen\n",
    "    for m in graph.user_items.get(user_idx, []):\n",
    "        scores[m] = float('-inf')\n",
    "    \n",
    "    _, top_idx = torch.topk(scores, top_k)\n",
    "    \n",
    "    recs = []\n",
    "    for idx in top_idx.numpy():\n",
    "        mid = graph.idx_to_movie[idx]\n",
    "        title = movies_df[movies_df['movie_id'] == mid].iloc[0]['title']\n",
    "        recs.append((title, scores[idx].item()))\n",
    "    return recs\n",
    "\n",
    "# Demo: Recommend for a random user\n",
    "user = np.random.randint(graph.num_users)\n",
    "uid = graph.idx_to_user[user]\n",
    "user_info = users_df[users_df['user_id'] == uid].iloc[0]\n",
    "\n",
    "print(f\"\\nüë§ User {uid}: {user_info['age']}yo {user_info['gender']}, {user_info['occupation']}\")\n",
    "\n",
    "# Show what they liked\n",
    "print(\"\\nüé¨ Movies they liked:\")\n",
    "for m in list(graph.user_items[user])[:5]:\n",
    "    mid = graph.idx_to_movie[m]\n",
    "    title = movies_df[movies_df['movie_id'] == mid].iloc[0]['title']\n",
    "    print(f\"   - {title}\")\n",
    "\n",
    "# Show recommendations  \n",
    "print(\"\\n‚ú® Top 10 Recommendations:\")\n",
    "for i, (title, score) in enumerate(recommend(model, user, graph, train_edges), 1):\n",
    "    print(f\"   {i:2d}. {title} (score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(losses, 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('BPR Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "epochs = list(range(10, 51, 10))\n",
    "hit10 = [m['Hit@10'] for m in metrics_history]\n",
    "ndcg10 = [m['NDCG@10'] for m in metrics_history]\n",
    "axes[1].plot(epochs, hit10, 'b-o', label='Hit@10', linewidth=2)\n",
    "axes[1].plot(epochs, ndcg10, 'r-o', label='NDCG@10', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Evaluation Metrics')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"Saved: training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings with t-SNE\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    u_emb, i_emb = model.get_embeddings(train_edges.to(device))\n",
    "    u_emb, i_emb = u_emb.cpu().numpy(), i_emb.cpu().numpy()\n",
    "\n",
    "# Sample for speed\n",
    "n = 300\n",
    "u_sample = u_emb[np.random.choice(len(u_emb), n, replace=False)]\n",
    "i_sample_idx = np.random.choice(len(i_emb), n, replace=False)\n",
    "i_sample = i_emb[i_sample_idx]\n",
    "\n",
    "combined = np.vstack([u_sample, i_sample])\n",
    "print(\"Running t-SNE (may take a minute)...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "coords = tsne.fit_transform(combined)\n",
    "\n",
    "u_coords = coords[:n]\n",
    "i_coords = coords[n:]\n",
    "\n",
    "# Get movie genres for coloring\n",
    "colors = []\n",
    "genre_list = ['Action', 'Comedy', 'Drama', 'Sci-Fi', 'Romance']\n",
    "for idx in i_sample_idx:\n",
    "    mid = graph.idx_to_movie[idx]\n",
    "    m = movies_df[movies_df['movie_id'] == mid].iloc[0]\n",
    "    color = 'gray'\n",
    "    for i, g in enumerate(genre_list):\n",
    "        if m.get(g, 0) == 1:\n",
    "            color = plt.cm.tab10(i)\n",
    "            break\n",
    "    colors.append(color)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axes[0].scatter(u_coords[:,0], u_coords[:,1], c='blue', alpha=0.5, s=20, label='Users')\n",
    "axes[0].scatter(i_coords[:,0], i_coords[:,1], c='red', alpha=0.5, s=20, label='Movies')\n",
    "axes[0].set_title('User vs Movie Embeddings')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].scatter(i_coords[:,0], i_coords[:,1], c=colors, alpha=0.6, s=30)\n",
    "axes[1].set_title('Movie Embeddings by Genre')\n",
    "for i, g in enumerate(genre_list):\n",
    "    axes[1].scatter([], [], c=plt.cm.tab10(i), label=g)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('embeddings.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"Saved: embeddings.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: How Message Passing Captures Peer Influence\n",
    "\n",
    "### The Magic of Multi-Hop Propagation:\n",
    "\n",
    "**Layer 0 (Initial):**\n",
    "- Each user/movie has a random embedding\n",
    "\n",
    "**Layer 1 (1-hop):**\n",
    "- User embedding ‚Üê aggregation of movies they liked\n",
    "- Movie embedding ‚Üê aggregation of users who liked it\n",
    "\n",
    "**Layer 2 (2-hop):**\n",
    "```\n",
    "User_A ‚Üí Movie_X ‚Üí User_B ‚Üí Movie_Y\n",
    "         (watched)  (also     (they\n",
    "                    watched)   liked)\n",
    "```\n",
    "\n",
    "Now User_A's embedding contains info about:\n",
    "- Movies they watched (1-hop)\n",
    "- **Other users** who watched those movies (2-hop)  \n",
    "- What those **similar users** liked (propagated through!)\n",
    "\n",
    "### Why This Works:\n",
    "\n",
    "1. **Similar users** (who liked similar movies) get **similar embeddings**\n",
    "2. **Similar movies** (liked by similar users) get **similar embeddings**  \n",
    "3. When we compute `dot(user_emb, movie_emb)`:\n",
    "   - High score = embeddings align\n",
    "   - The user embedding \"points toward\" movies they'd like!\n",
    "\n",
    "### Collaborative Filtering Emerges Automatically!\n",
    "\n",
    "No explicit \"find similar users\" step needed. The graph structure + message passing discovers these relationships naturally through the mathematics of aggregation.\n",
    "\n",
    "---\n",
    "\n",
    "### Congratulations! üéâ\n",
    "\n",
    "You've built a working GNN-based recommendation system that:\n",
    "1. Constructs a bipartite user-movie graph\n",
    "2. Learns embeddings through message passing\n",
    "3. Captures peer influence via multi-hop propagation\n",
    "4. Generates personalized recommendations\n",
    "5. Evaluates using Hit@K and NDCG@K"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
